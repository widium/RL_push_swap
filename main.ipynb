{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UoKOjwlLRDpk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import nan\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tabulate import tabulate\n",
        "import random\n",
        "from itertools import zip_longest\n",
        "from collections import namedtuple\n",
        "from stack import Stack\n",
        "from actions import Moove, Action, List_actions\n",
        "from utils_class import EpsilonGreedy, ReplayMemory\n",
        "from DQN import DQNAgent\n",
        "from env import Env \n",
        "from constant import *\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SJ6oCEKZRDpo"
      },
      "outputs": [],
      "source": [
        "size = 10\n",
        "env = Env(size)\n",
        "# print(env.state().shape[0])\n",
        "agent = DQNAgent(size, len(env.action_space()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STATESSSSS [[[97. 39. 74. 54. 35. 53. 37. 27. 77. 18.]\n",
            "  [nan nan nan nan nan nan nan nan nan nan]]\n",
            "\n",
            " [[39. 74. 54. 35. 53. 37. 27. 77. 18. 97.]\n",
            "  [nan nan nan nan nan nan nan nan nan nan]]]\n",
            "(2, 2, 10)\n",
            "Unexpected exception formatting exception. Falling back to standard exception\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipykernel_203447/527718494.py\", line 27, in <cell line: 2>\n",
            "    agent.train(states, next_states, experiences)\n",
            "  File \"/home/widium/Programming/AI/RL_push_swap/DQN.py\", line 39, in train\n",
            "    Q_policy_list = self.policy_model.predict(states)\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n",
            "        outputs = model.predict_step(data)\n",
            "    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n",
            "        return self(x, training=False)\n",
            "    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "        raise e.with_traceback(filtered_tb) from None\n",
            "    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n",
            "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
            "\n",
            "    ValueError: Input 0 of layer \"sequential_6\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 2, 10)\n",
            "\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 1992, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
            "    frames.append(self.format_record(r))\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
            "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
            "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/stack_data/core.py\", line 698, in lines\n",
            "    pieces = self.included_pieces\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
            "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
            "    pos = scope_pieces.index(self.executing_piece)\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
            "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
            "    return only(\n",
            "  File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/executing/executing.py\", line 164, in only\n",
            "    raise NotOneValueFound('Expected one value, found 0')\n",
            "executing.executing.NotOneValueFound: Expected one value, found 0\n"
          ]
        }
      ],
      "source": [
        "episode_durations = list()\n",
        "for episode in range(EPISODE):\n",
        "    \n",
        "    env.reset(STACK_SIZE)\n",
        "    state = env.state()\n",
        "    # env.print_state()\n",
        "    \n",
        "    # while not (env.state == 'done'):\n",
        "    timesteps = 0\n",
        "    for i in range(2):\n",
        "        \n",
        "        timesteps += 1;\n",
        "        action = env.choose_action(agent.policy_model(state))\n",
        "        reward = env.reward()\n",
        "        next_state = env.state()\n",
        "        \n",
        "        experience = env.create_experience(state, action, next_state, reward)\n",
        "        env.replaymemory.push(experience)\n",
        "        # env.print_experience(experience)\n",
        "        state = next_state\n",
        "\n",
        "        if env.replaymemory.can_provide_sample(BATCH_SIZE):\n",
        "            \n",
        "            experiences = env.replaymemory.get_sample(BATCH_SIZE)\n",
        "            states, actions, next_states, rewards = env.replaymemory.extract_value(experiences)\n",
        "            # env.replaymemory.print_buffer(experiences)\n",
        "            agent.train(states, next_states, experiences)\n",
        "        \n",
        "\n",
        "    if (env.state == 'done'):\n",
        "        episode_durations.append(timesteps)\n",
        "plt.plot(episode_durations)    \n",
        "            \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---State t---\n",
            "-A-\t-B-\n",
            "___________\t\n",
            "|52.0\t4.0|\n",
            "|15.0\t92.0|\n",
            "|48.0\tnan|\n",
            "|68.0\tnan|\n",
            "|8.0\tnan|\n",
            "|89.0\tnan|\n",
            "|78.0\tnan|\n",
            "|60.0\tnan|\n",
            "|nan\tnan|\n",
            "|nan\tnan|\n",
            "___________\t\n"
          ]
        }
      ],
      "source": [
        "# env.print_stack()\n",
        "# env.moover.push_b()\n",
        "# env.choose_action()\n",
        "env.current_action = 0\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "env.current_action = 1\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "env.current_action = 0\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "# print(env.experience)\n",
        "env.print_state()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Experience(state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), action=1, next_state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), reward=-6),\n",
              " Experience(state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), action=0, next_state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), reward=-1),\n",
              " Experience(state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), action=0, next_state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), reward=-6),\n",
              " Experience(state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), action=0, next_state=array([[nan, nan, 13., 27., 84., 58., 93., 67., 35., 11.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, 26., 71.]], dtype=float32), reward=-1)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.replaymemory.get_sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions : 0 \t Reward : -1\n",
            "Actions : 1 \t Reward : -6\n",
            "Actions : 0 \t Reward : -6\n",
            "Actions : 0 \t Reward : -1\n"
          ]
        }
      ],
      "source": [
        "env.replaymemory.print_history(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "env.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7af6488317c4eae45cfe2d92ddcd760ac10ac76eee454fa0eead8075769044a8"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 ('tf_gpu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
