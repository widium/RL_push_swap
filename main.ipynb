{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "UoKOjwlLRDpk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import nan\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import print_state, print_experience, print_buffer\n",
        "from constant import *\n",
        "\n",
        "\n",
        "from DQN import DQNAgent\n",
        "from env import Env\n",
        "\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SJ6oCEKZRDpo"
      },
      "outputs": [],
      "source": [
        "size = 10\n",
        "env = Env(size)\n",
        "# print(env.state().shape[0])\n",
        "agent = DQNAgent(size, len(env.action_space()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---State t---\n",
            "-A-\t-B-\n",
            "___________\t\n",
            "|78.0\tnan|\n",
            "|22.0\tnan|\n",
            "|29.0\tnan|\n",
            "|40.0\tnan|\n",
            "|68.0\tnan|\n",
            "|62.0\tnan|\n",
            "|19.0\tnan|\n",
            "|89.0\tnan|\n",
            "|60.0\tnan|\n",
            "|79.0\tnan|\n",
            "___________\t\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|78.0\tnan|\t\t|22.0\tnan|\n",
            "|22.0\tnan|\t\t|78.0\tnan|\n",
            "|29.0\tnan|\t\t|29.0\tnan|\n",
            "|40.0\tnan|\t\t|40.0\tnan|\n",
            "|68.0\tnan|\t\t|68.0\tnan|\n",
            "|62.0\tnan|\t\t|62.0\tnan|\n",
            "|19.0\tnan|\t\t|19.0\tnan|\n",
            "|89.0\tnan|\t\t|89.0\tnan|\n",
            "|60.0\tnan|\t\t|60.0\tnan|\n",
            "|79.0\tnan|\t\t|79.0\tnan|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [7]\n",
            "\tReward [-1]\n",
            "----------------------------------\n",
            "========== BUFFER ==========\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|78.0\tnan|\t\t|22.0\tnan|\n",
            "|22.0\tnan|\t\t|78.0\tnan|\n",
            "|29.0\tnan|\t\t|29.0\tnan|\n",
            "|40.0\tnan|\t\t|40.0\tnan|\n",
            "|68.0\tnan|\t\t|68.0\tnan|\n",
            "|62.0\tnan|\t\t|62.0\tnan|\n",
            "|19.0\tnan|\t\t|19.0\tnan|\n",
            "|89.0\tnan|\t\t|89.0\tnan|\n",
            "|60.0\tnan|\t\t|60.0\tnan|\n",
            "|79.0\tnan|\t\t|79.0\tnan|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [7]\n",
            "\tReward [-1]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|26.0\tnan|\t\t|26.0\tnan|\n",
            "|40.0\tnan|\t\t|40.0\tnan|\n",
            "|96.0\tnan|\t\t|96.0\tnan|\n",
            "|77.0\tnan|\t\t|77.0\tnan|\n",
            "|35.0\tnan|\t\t|35.0\tnan|\n",
            "|82.0\tnan|\t\t|82.0\tnan|\n",
            "|74.0\tnan|\t\t|74.0\tnan|\n",
            "|47.0\tnan|\t\t|47.0\tnan|\n",
            "|10.0\tnan|\t\t|10.0\tnan|\n",
            "|11.0\tnan|\t\t|11.0\tnan|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [1]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "========== [2 experience ] ==========\n",
            "(2, 2, 10)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_20\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 2, 10)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/widium/Programming/AI/RL_push_swap/main.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/widium/Programming/AI/RL_push_swap/main.ipynb#ch0000003?line=24'>25</a>\u001b[0m         states, actions, next_states, rewards \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreplaymemory\u001b[39m.\u001b[39mextract_value(buffer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/widium/Programming/AI/RL_push_swap/main.ipynb#ch0000003?line=25'>26</a>\u001b[0m         print_buffer(buffer)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/widium/Programming/AI/RL_push_swap/main.ipynb#ch0000003?line=26'>27</a>\u001b[0m         agent\u001b[39m.\u001b[39;49mtrain(states, next_states, buffer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/widium/Programming/AI/RL_push_swap/main.ipynb#ch0000003?line=29'>30</a>\u001b[0m \u001b[39mif\u001b[39;00m (env\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdone\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/widium/Programming/AI/RL_push_swap/main.ipynb#ch0000003?line=30'>31</a>\u001b[0m     episode_durations\u001b[39m.\u001b[39mappend(timesteps)\n",
            "File \u001b[0;32m~/Programming/AI/RL_push_swap/DQN.py:37\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[0;34m(self, states, next_states, experiences)\u001b[0m\n\u001b[1;32m     <a href='file:///home/widium/Programming/AI/RL_push_swap/DQN.py?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(states\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='file:///home/widium/Programming/AI/RL_push_swap/DQN.py?line=34'>35</a>\u001b[0m \u001b[39m# print(next_states)\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/widium/Programming/AI/RL_push_swap/DQN.py?line=35'>36</a>\u001b[0m \u001b[39m##--------Recuperer toutes les Q values des 2 model-----##\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/widium/Programming/AI/RL_push_swap/DQN.py?line=36'>37</a>\u001b[0m Q_policy_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_model\u001b[39m.\u001b[39;49mpredict(states)\n\u001b[1;32m     <a href='file:///home/widium/Programming/AI/RL_push_swap/DQN.py?line=37'>38</a>\u001b[0m Q_target_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_model\u001b[39m.\u001b[39mpredict(next_states)\n\u001b[1;32m     <a href='file:///home/widium/Programming/AI/RL_push_swap/DQN.py?line=40'>41</a>\u001b[0m X \u001b[39m=\u001b[39m []\n",
            "File \u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1126'>1127</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1127'>1128</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1128'>1129</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1129'>1130</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py?line=1130'>1131</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_20\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 2, 10)\n"
          ]
        }
      ],
      "source": [
        "episode_durations = list()\n",
        "for episode in range(EPISODE):\n",
        "    \n",
        "    env.reset(STACK_SIZE)\n",
        "    state = env.state()\n",
        "    print_state(env.A, env.B)\n",
        "    \n",
        "    # while not (env.state == 'done'):\n",
        "    timesteps = 0\n",
        "    for i in range(2):\n",
        "        \n",
        "        timesteps += 1;\n",
        "        action = env.choose_action(agent.policy_model(state))\n",
        "        reward = env.reward()\n",
        "        next_state = env.state()\n",
        "        \n",
        "        experience = env.create_experience(state, action, next_state, reward)\n",
        "        env.replaymemory.push(experience)\n",
        "        print_experience(experience)\n",
        "        state = next_state\n",
        "\n",
        "        if env.replaymemory.can_provide_sample(BATCH_SIZE):\n",
        "            \n",
        "            buffer = env.replaymemory.get_sample(BATCH_SIZE)\n",
        "            states, actions, next_states, rewards = env.replaymemory.extract_value(buffer)\n",
        "            print_buffer(buffer)\n",
        "            agent.train(states, next_states, buffer)\n",
        "        \n",
        "\n",
        "    if (env.state == 'done'):\n",
        "        episode_durations.append(timesteps)\n",
        "plt.plot(episode_durations)    \n",
        "            \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---State t---\n",
            "-A-\t-B-\n",
            "___________\t\n",
            "|52.0\t4.0|\n",
            "|15.0\t92.0|\n",
            "|48.0\tnan|\n",
            "|68.0\tnan|\n",
            "|8.0\tnan|\n",
            "|89.0\tnan|\n",
            "|78.0\tnan|\n",
            "|60.0\tnan|\n",
            "|nan\tnan|\n",
            "|nan\tnan|\n",
            "___________\t\n"
          ]
        }
      ],
      "source": [
        "# env.print_stack()\n",
        "# env.moover.push_b()\n",
        "# env.choose_action()\n",
        "env.current_action = 0\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "env.current_action = 1\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "env.current_action = 0\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "env.take_actions()\n",
        "env.create_experience()\n",
        "env.replaymemory.push(env.experience)\n",
        "# print(env.experience)\n",
        "env.print_state()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Experience(state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), action=1, next_state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), reward=-6),\n",
              " Experience(state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), action=0, next_state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), reward=-1),\n",
              " Experience(state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), action=0, next_state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), reward=-6),\n",
              " Experience(state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), action=0, next_state=array([[nan, nan, 13., 27., 84., 58., 93., 67., 35., 11.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, 26., 71.]], dtype=float32), reward=-1)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.replaymemory.get_sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions : 0 \t Reward : -1\n",
            "Actions : 1 \t Reward : -6\n",
            "Actions : 0 \t Reward : -6\n",
            "Actions : 0 \t Reward : -1\n"
          ]
        }
      ],
      "source": [
        "env.replaymemory.print_history(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "env.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7af6488317c4eae45cfe2d92ddcd760ac10ac76eee454fa0eead8075769044a8"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 ('tf_gpu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
