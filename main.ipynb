{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UoKOjwlLRDpk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-07 08:52:36.790501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-07 08:52:36.790671: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "/home/widium/.conda/envs/tf_gpu/lib/python3.8/site-packages/tensorflow/python/client/session.py:1771: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from numpy import nan\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from verbose import print_state, print_experience, print_buffer, print_shapes, action_available, print_interaction\n",
        "# from utils import \n",
        "from constant import *\n",
        "\n",
        "\n",
        "from DQN import DQNAgent\n",
        "from env import Env\n",
        "from utils_class import EpsilonGreedy\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = InteractiveSession(config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SJ6oCEKZRDpo"
      },
      "outputs": [],
      "source": [
        "STACK_SIZE = 3\n",
        "NBR_STACK = 2\n",
        "\n",
        "env = Env(STACK_SIZE)\n",
        "strategy = EpsilonGreedy(MIN_EPSILON, START_EPSILON, DECAY)\n",
        "agent = DQNAgent(NBR_STACK, STACK_SIZE, len(env.action_space()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---State t---\n",
            "-A-\t-B-\n",
            "___________\t\n",
            "|17.0\tnan|\n",
            "|87.0\tnan|\n",
            "|57.0\tnan|\n",
            "___________\t\n",
            "------------\n",
            "Env : in progress\n",
            "------------\n"
          ]
        }
      ],
      "source": [
        "print_state(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Actions available ===\n",
            "rotate_a\n",
            "inverse_rotate_a\n",
            "swap_a\n",
            "push_b\n",
            "=============\n",
            "---State t---\n",
            "-A-\t-B-\n",
            "___________\t\n",
            "|17.0\tnan|\n",
            "|87.0\tnan|\n",
            "|57.0\tnan|\n",
            "___________\t\n",
            "------------\n",
            "Env : in progress\n",
            "------------\n",
            "----------------------------------\n",
            "Action [rotate_a]\n",
            "Reward [-1]\n",
            "----------------------------------\n",
            "=== Actions available ===\n",
            "rotate_a\n",
            "inverse_rotate_a\n",
            "swap_a\n",
            "push_b\n",
            "=============\n",
            "---State t---\n",
            "-A-\t-B-\n",
            "___________\t\n",
            "|57.0\tnan|\n",
            "|17.0\tnan|\n",
            "|87.0\tnan|\n",
            "___________\t\n",
            "------------\n",
            "Env : in progress\n",
            "------------\n",
            "----------------------------------\n",
            "Action [swap_a]\n",
            "Reward [99]\n",
            "----------------------------------\n",
            "---State t---\n",
            "-A-\t-B-\n",
            "___________\t\n",
            "|17.0\tnan|\n",
            "|57.0\tnan|\n",
            "|87.0\tnan|\n",
            "___________\t\n",
            "------------\n",
            "Env : done\n",
            "------------\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWA0lEQVR4nO3df5Bd5X3f8fcnCBHH2JWADSGSQNjGNTJxBdkIOnQyGDe2YCaGUMaFP4CoUCUT7EKLM2DcGdzEmQFaQ800A1UKAWcIkAAamISUECOXegrCK7H8EIIgCzxIkc0GDCKhwRH+9o97VF+W/XF39+4u4rxfM2f2nOfHuc/DzuxH58flSVUhSWqfn5rvAUiS5ocBIEktZQBIUksZAJLUUgaAJLXUgvkewFQccsghtXz58vkehiTtUzZt2vS3VTUwunyfCoDly5czNDQ038OQpH1Kku+NVe4tIElqKQNAklrKAJCkljIAJKmlDABJaqlJAyDJsiQbkjydZEuSi8Zo87EkDyd5M8kXR9WtTvJskm1JLusqPzLJxqb8jiQL+zMlSVIverkC2ANcUlUrgBOAC5OsGNXmFeDfAf+luzDJfsDvA6cAK4Czu/peBVxbVR8BfgicP+1ZSJKmbNIAqKpdVbW52X8d2AosGdXmpar6DvCPo7qvArZV1faq+hFwO3BakgAnA3c27W4BTp/JRCRJUzOlZwBJlgPHAht77LIEeLHreEdTdjDwalXtGVU+1meuTTKUZGhkZGQqw5UkTaDnAEhyIHAXcHFV7Z69Ib1dVa2rqsGqGhwYeMc3mSVJ09RTACTZn84f/1ur6u4pnH8nsKzreGlT9jKwKMmCUeWSpDnSy1tAAW4EtlbVNVM8/3eAo5o3fhYCZwH3Vmcdyg3AmU2784B7pnhuSdIM9PI/gzsROAd4MslwU3Y5cDhAVd2Q5OeAIeCDwI+TXAysqKrdST4P3A/sB9xUVVuac1wK3J7kq8BjdEJGkjRHJg2Aqvo2kEnafJ/ObZyx6u4D7hujfDudt4QkSfPAbwJLUksZAJLUUgaAJLWUASBJLWUASFJLGQCS1FIGgCS1lAEgSS1lAEhSSxkAktRSBoAktZQBIEktZQBIUksZAJLUUgaAJLWUASBJLdXLkpDLkmxI8nSSLUkuGqNNklyXZFuSJ5Ic15R/Mslw1/YPSU5v6m5O8nxX3cp+T06SNL5eloTcA1xSVZuTfADYlOSBqnq6q80pwFHNdjxwPXB8VW0AVgIkOQjYBvxlV7/frqo7Zz4NSdJUTXoFUFW7qmpzs/86sBVYMqrZacA3quMRYFGSw0a1ORP4i6p6ow/jliTN0JSeASRZDhwLbBxVtQR4set4B+8MibOA20aV/V5zy+jaJAeM85lrkwwlGRoZGZnKcCVJE+g5AJIcCNwFXFxVu6fyIc3VwC8A93cVfwn4GPBLwEHApWP1rap1VTVYVYMDAwNT+VhJ0gR6CoAk+9P5439rVd09RpOdwLKu46VN2V6fA9ZX1T/uLWhuLVVVvQn8IbBqqoOXJE1fL28BBbgR2FpV14zT7F7g3OZtoBOA16pqV1f92Yy6/bP3GUFz/tOBp6Y+fEnSdPXyFtCJwDnAk0mGm7LLgcMBquoG4D7gVDpv+bwBrNnbuXlusAz4X6POe2uSASDAMPCb05yDJGkaJg2Aqvo2nT/SE7Up4MJx6l7gnQ+EqaqTexuiJGk2+E1gSWopA0CSWsoAkKSWMgAkqaUMAElqKQNAklrKAJCkljIAJKmlDABJaikDQJJaygCQpJYyACSppQwASWopA0CSWsoAkKSWMgAkqaV6WRJyWZINSZ5OsiXJRWO0SZLrkmxL8kSS47rq3koy3Gz3dpUfmWRj0+eOJAv7Ny1J0mR6uQLYA1xSVSuAE4ALk6wY1eYU4KhmWwtc31X3f6tqZbN9tqv8KuDaqvoI8EPg/OlOQpI0dZMGQFXtqqrNzf7rwFbeucTjacA3quMRYNHeRd/H0iwEfzJwZ1N0C52F4SVJc2RKzwCaBd6PBTaOqloCvNh1vIOfhMRPJxlK8kiS05uyg4FXq2rPGO1Hf+bapv/QyMjIVIYrSZrApIvC75XkQOAu4OKq2j2FzziiqnYm+RDwYJIngdd67VxV64B1AIODgzWFz5UkTaCnK4Ak+9P5439rVd09RpOdwLKu46VNGVW19+d24Ft0riBepnObaMHo9pKkudHLW0ABbgS2VtU14zS7Fzi3eRvoBOC1qtqVZHGSA5rzHAKcCDxdVQVsAM5s+p8H3DPDuUiSpqCXW0AnAucATyYZbsouBw4HqKobgPuAU4FtwBvAmqbd0cB/T/JjOmFzZVU93dRdCtye5KvAY3RCRpI0RyYNgKr6NpBJ2hRw4Rjl/wf4hXH6bAdW9TZMSVK/+U1gSWopA0CSWsoAkKSWMgAkqaUMAElqKQNAklrKAJCkljIAJKmlDABJaikDQJJaygCQpJYyACSppQwASWopA0CSWsoAkKSW6mVFsGVJNiR5OsmWJBeN0SZJrkuyLckTSY5rylcmebjp90SSf93V5+YkzycZbraVfZ2ZJGlCvawItge4pKo2J/kAsCnJA10rewGcAhzVbMcD1zc/3wDOrarnkvx80/f+qnq16ffbVXVnvyYjSepdLyuC7QJ2NfuvJ9kKLAG6A+A04BvNymCPJFmU5LCq+uuu8/xNkpeAAeDVPs5BkjQNU3oGkGQ5cCywcVTVEuDFruMdTVl331XAQuC7XcW/19waunbv4vFjfObaJENJhkZGRqYyXEnSBHoOgCQHAncBF1fV7ql8SJLDgD8C1lTVj5viLwEfA34JOIjOIvHvUFXrqmqwqgYHBgam8rGSpAn0FABJ9qfzx//Wqrp7jCY7gWVdx0ubMpJ8EPhz4MtV9cjeBlW1qzreBP4QF4iXpDnVy1tAAW4EtlbVNeM0uxc4t3kb6ATgtaralWQhsJ7O84G3Pextrgr2nv904KnpT0OSNFW9vAV0InAO8GSS4abscuBwgKq6AbgPOBXYRufNnzVNu88BvwwcnOTXm7Jfr6ph4NYkA0CAYeA3ZzYVSdJUpPPizr5hcHCwhoaG5nsYkrRPSbKpqgZHl/tNYElqKQNAklrKAJCkljIAJKmlDABJaikDQJJaygCQpJYyACSppQwASWopA0CSWsoAkKSWMgAkqaUMAElqKQNAklrKAJCkljIAJKmlelkSclmSDUmeTrIlyUVjtEmS65JsS/JEkuO66s5L8lyznddV/otJnmz6XNcsDSlJmiO9XAHsAS6pqhXACcCFSVaManMKcFSzrQWuB0hyEHAFcDydRd+vSLK46XM98G+7+q2e2VQkSVMxaQBU1a6q2tzsvw5sBZaManYanYXfq6oeARY1i75/Bnigql6pqh8CDwCrm7oPVtUj1VmT8ht0FoaXJM2RKT0DSLIcOBbYOKpqCfBi1/GOpmyi8h1jlI/1mWuTDCUZGhkZmcpwJUkT6DkAkhwI3AVcXFW7Z29Ib1dV66pqsKoGBwYG5upjJek9r6cASLI/nT/+t1bV3WM02Qks6zpe2pRNVL50jHJJ0hzp5S2gADcCW6vqmnGa3Quc27wNdALwWlXtAu4HPp1kcfPw99PA/U3d7iQnNOc/F7inHxOSJPVmQQ9tTgTOAZ5MMtyUXQ4cDlBVNwD3AacC24A3gDVN3StJfhf4TtPvd6rqlWb/t4CbgfcBf9FskqQ5ks5LOPuGwcHBGhoamu9hSNI+JcmmqhocXe43gSWppQwASWopA0CSWsoAkKSWMgAkqaUMAElqKQNAklrKAJCkljIAJKmlDABJaikDQJJaygCQpJYyACSppQwASWopA0CSWsoAkKSW6mVJyJuSvJTkqXHqFydZn+SJJI8mOaYp/6dJhru23Ukubuq+kmRnV92pfZ2VJGlSvVwB3AysnqD+cmC4qj5BZ23frwNU1bNVtbKqVgK/SGepyPVd/a7dW19V901n8JKk6Zs0AKrqIeCVCZqsAB5s2j4DLE9y6Kg2nwK+W1Xfm+5AJUn91Y9nAI8DZwAkWQUcASwd1eYs4LZRZZ9vbhvdlGTxeCdPsjbJUJKhkZGRPgxXkgT9CYArgUVJhoEvAI8Bb+2tTLIQ+Czwp119rgc+DKwEdgFfG+/kVbWuqgaranBgYKAPw5UkASyY6QmqajewBiBJgOeB7V1NTgE2V9UPuvr8//0kfwD82UzHIUmamhlfASRZ1PwrH+AC4KEmFPY6m1G3f5Ic1nX4a8CYbxhJkmbPpFcASW4DTgIOSbIDuALYH6CqbgCOBm5JUsAW4Pyuvu8HfgX4jVGnvTrJSqCAF8aolyTNskkDoKrOnqT+YeCj49T9PXDwGOXn9DpASdLs8JvAktRSBoAktZQBIEktZQBIUksZAJLUUgaAJLWUASBJLWUASFJLGQCS1FIGgCS1lAEgSS1lAEhSSxkAktRSBoAktZQBIEktNWkANIu2v5RkzFW7kixOsr5Z4P3RJMd01b2Q5Mkkw0mGusoPSvJAkuean+MuCi9Jmh29XAHcDKyeoP5yYLiqPgGcC3x9VP0nq2plVQ12lV0GfLOqjgK+2RxLkubQpAFQVQ8Br0zQZAXwYNP2GWB5kkMnOe1pwC3N/i3A6ZOOVJLUV/14BvA4cAZAklXAEcDSpq6Av0yyKcnarj6HVtWuZv/7wLiBkWRtkqEkQyMjI30YriQJ+hMAVwKLkgwDXwAeA95q6v5FVR0HnAJcmOSXR3euqqITFGOqqnVVNVhVgwMDA30YriQJelgUfjJVtRtYA5AkwPPA9qZuZ/PzpSTrgVXAQ8APkhxWVbuSHAa8NNNxSJKmZsZXAEkWJVnYHF4APFRVu5O8P8kHmjbvBz4N7H2T6F7gvGb/POCemY5DkjQ1k14BJLkNOAk4JMkO4Apgf4CqugE4GrglSQFbgPObrocC6zsXBSwA/riq/mdTdyXwJ0nOB74HfK5fE5Ik9WbSAKiqsyepfxj46Bjl24F/Nk6fl4FP9ThGSdIs8JvAktRSBoAktZQBIEktZQBIUksZAJLUUgaAJLWUASBJLWUASFJLGQCS1FIGgCS1lAEgSS1lAEhSSxkAktRSBoAktZQBIEktZQBIUktNGgBJbkryUpKnxqlfnGR9kieSPJrkmKZ8WZINSZ5OsiXJRV19vpJkZ5LhZju1f1OSJPWilyuAm4HVE9RfDgxX1SeAc4GvN+V7gEuqagVwAnBhkhVd/a6tqpXNdt/Uhy5JmolJA6CqHgJemaDJCuDBpu0zwPIkh1bVrqra3JS/DmwFlsx8yJKkfujHM4DHgTMAkqwCjgCWdjdIshw4FtjYVfz55rbRTUkWj3fyJGuTDCUZGhkZ6cNwJUnQnwC4EliUZBj4AvAY8NbeyiQHAncBF1fV7qb4euDDwEpgF/C18U5eVeuqarCqBgcGBvowXEkSwIKZnqD5o74GIEmA54HtzfH+dP7431pVd3f1+cHe/SR/APzZTMchSZqaGV8BJFmUZGFzeAHwUFXtbsLgRmBrVV0zqs9hXYe/Boz5hpEkafZMegWQ5DbgJOCQJDuAK4D9AarqBuBo4JYkBWwBzm+6ngicAzzZ3B4CuLx54+fqJCuBAl4AfqM/05Ek9WrSAKiqsyepfxj46Bjl3wYyTp9zeh2gJGl2+E1gSWopA0CSWsoAkKSWMgAkqaUMAElqKQNAklrKAJCkljIAJKmlDABJaikDQJJaygCQpJYyACSppQwASWopA0CSWsoAkKSWMgAkqaV6CoAkNyV5KcmYSzcmWZxkfZInkjya5JiuutVJnk2yLcllXeVHJtnYlN/RtaykJGkO9HoFcDOweoL6y4HhqvoEcC7wdYAk+wG/D5wCrADOTrKi6XMVcG1VfQT4IT9ZSlKSNAd6CoCqegh4ZYImK4AHm7bPAMuTHAqsArZV1faq+hFwO3Bas2D8ycCdTf9bgNOnNQNJ0rT06xnA48AZAElWAUcAS4ElwItd7XY0ZQcDr1bVnlHl75BkbZKhJEMjIyN9Gq4kqV8BcCWwKMkw8AXgMeCtfpy4qtZV1WBVDQ4MDPTjlJIkYEE/TlJVu4E1AM3tneeB7cD7gGVdTZcCO4GX6QTGguYqYG+5JGmO9OUKIMmirrd4LgAeakLhO8BRzRs/C4GzgHurqoANwJlNn/OAe/oxFklSb3q6AkhyG3AScEiSHcAVwP4AVXUDcDRwS5ICttC80VNVe5J8Hrgf2A+4qaq2NKe9FLg9yVfp3DK6sV+TkiRNLp1/jO8bBgcHa2hoaL6HIUn7lCSbqmpwdLnfBJakljIAJKmlDABJaikDQJJaap96CJxkBPjefI9jGg4B/na+BzGH2jZfcM5tsa/O+Yiqesc3afepANhXJRka6wn8e1Xb5gvOuS3ea3P2FpAktZQBIEktZQDMjXXzPYA51rb5gnNui/fUnH0GIEkt5RWAJLWUASBJLWUA9EmSg5I8kOS55uficdqd17R5Lsl5Y9Tfm+Sp2R/xzMxkvkl+JsmfJ3kmyZYkV87t6KcmyeokzybZluSyMeoPSHJHU78xyfKuui815c8m+cycDnwGpjvnJL+SZFOSJ5ufJ8/54KdpJr/npv7wJH+X5ItzNuiZqiq3PmzA1cBlzf5lwFVjtDmIzkI5BwGLm/3FXfVnAH8MPDXf85nN+QI/A3yyabMQ+N/AKfM9p3HmuR/wXeBDzVgfB1aMavNbwA3N/lnAHc3+iqb9AcCRzXn2m+85zfKcjwV+vtk/Btg53/OZ7Tl31d8J/CnwxfmeT6+bVwD9cxqdxe1h/EXuPwM8UFWvVNUPgQeA1QBJDgT+A/DV2R9qX0x7vlX1RlVtAKiqHwGb6awK9260CthWVdubsd5OZ+7duv9b3Al8qlkZ7zTg9qp6s6qeB7Y153u3m/acq+qxqvqbpnwL8L4kB8zJqGdmJr9nkpxOZyXELexDDID+ObSqdjX73wcOHaPNEuDFruMdTRnA7wJfA96YtRH210znC3RWkwN+FfjmLIyxHyadQ3eb6ixx+hpwcI99341mMudu/wrYXFVvztI4+2nac27+8XYp8J/mYJx91Zc1gdsiyV8BPzdG1Ze7D6qqmtXRej3vSuDDVfXvR99XnE+zNd+u8y8AbgOuq6rt0xul3o2SfBy4Cvj0fI9lDnwFuLaq/q65INhnGABTUFX/cry6JD9IclhV7UpyGPDSGM120llac6+lwLeAfw4MJnmBzu/kZ5N8q6pOYh7N4nz3Wgc8V1X/deajnTU7gWVdx0ubsrHa7GhC7Z8AL/fY991oJnMmyVJgPXBuVX139ofbFzOZ8/HAmUmuBhYBP07yD1X132Z91DM13w8h3isb8J95+0PRq8docxCd+4SLm+154KBRbZazbzwEntF86TzruAv4qfmeyyTzXEDn4fWR/OTh4MdHtbmQtz8c/JNm/+O8/SHwdvaNh8AzmfOipv0Z8z2PuZrzqDZfYR96CDzvA3ivbHTuf34TeA74q64/dIPA/+hq92/oPAzcBqwZ4zz7SgBMe750/nVVwFZguNkumO85TTDXU4G/pvOWyJebst8BPtvs/zSdtz+2AY8CH+rq++Wm37O8S9906uecgf8I/H3X73UY+Nn5ns9s/567zrFPBYD/KwhJainfApKkljIAJKmlDABJaikDQJJaygCQpJYyACSppQwASWqp/wf/Nd3tF2ZEzwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "episode_durations = list()\n",
        "for episode in range(EPISODE):\n",
        "    \n",
        "    # env.reset(STACK_SIZE)\n",
        "    state = env.get_state()\n",
        "    \n",
        "    timesteps = 0\n",
        "    while (1):\n",
        "        \n",
        "        action_available(env)\n",
        "        print_state(env)\n",
        "        timesteps += 1\n",
        "        \n",
        "        exploration_rate = strategy.get_exploration_rate(timesteps)\n",
        "        \n",
        "        action = env.choose_action(state, agent.policy_model, exploration_rate)\n",
        "        reward = env.reward()\n",
        "        next_state = env.get_state()\n",
        "        print_interaction(action, reward)\n",
        "        \n",
        "        \n",
        "        \n",
        "        experience = env.create_experience(state, action, next_state, reward)\n",
        "        env.replaymemory.push(experience)\n",
        "        state = next_state\n",
        "        \n",
        "        # print_experience(experience)\n",
        "        # print(\"==== Dehors ===\")\n",
        "        if env.replaymemory.can_provide_sample(BATCH_SIZE):\n",
        "            print(\"======== START TRAIN ========\")\n",
        "            \n",
        "            buffer = env.replaymemory.get_sample(BATCH_SIZE)\n",
        "            # print_buffer(buffer)\n",
        "            \n",
        "            states, actions, next_states, rewards, dones = env.replaymemory.extract_value(buffer)\n",
        "            # print_shapes(states, next_states)\n",
        "            agent.train(states, next_states, buffer)\n",
        "        \n",
        "        # print(f\"Env : {env.state()}\")\n",
        "        if (env.state() == 'done'):\n",
        "            print_state(env)\n",
        "            episode_durations.append(timesteps)\n",
        "            plt.plot(episode_durations)\n",
        "            break\n",
        "            \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== BUFFER ==========\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [rotate_a]\n",
            "\tReward [-10]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [swap_a]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [push_b]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [rotate_a]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [swap_a]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [push_b]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [rotate_a]\n",
            "\tReward [-10]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [swap_a]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [inverse_rotate_a]\n",
            "\tReward [-10]\n",
            "----------------------------------\n",
            "---State t---\t\t---State t+1---\n",
            "-A-\t-B-\t\t-A-\t-B-\n",
            "___________\t\t___________\n",
            "|nan\t7.0|\t\t|nan\t7.0|\n",
            "|nan\t90.0|\t\t|nan\t90.0|\n",
            "|nan\t0.0|\t\t|nan\t0.0|\n",
            "___________\t\t___________\n",
            "----------------------------------\n",
            "\tAction [inverse_rotate_a]\n",
            "\tReward [-5]\n",
            "----------------------------------\n",
            "========== [10 experience ] ==========\n"
          ]
        }
      ],
      "source": [
        "print_buffer(buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Experience(state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), action=1, next_state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), reward=-6),\n",
              " Experience(state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), action=0, next_state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), reward=-1),\n",
              " Experience(state=array([[13., 27., 84., 58., 93., 67., 35., 11., 71., 26.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32), action=0, next_state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), reward=-6),\n",
              " Experience(state=array([[nan, 13., 27., 84., 58., 93., 67., 35., 11., 71.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, 26.]], dtype=float32), action=0, next_state=array([[nan, nan, 13., 27., 84., 58., 93., 67., 35., 11.],\n",
              "        [nan, nan, nan, nan, nan, nan, nan, nan, 26., 71.]], dtype=float32), reward=-1)]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.replaymemory.get_sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actions : 0 \t Reward : -1\n",
            "Actions : 1 \t Reward : -6\n",
            "Actions : 0 \t Reward : -6\n",
            "Actions : 0 \t Reward : -1\n"
          ]
        }
      ],
      "source": [
        "env.replaymemory.print_history(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "env.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7af6488317c4eae45cfe2d92ddcd760ac10ac76eee454fa0eead8075769044a8"
    },
    "kernelspec": {
      "display_name": "Python 3.8.0 ('tf_gpu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
